{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93d63f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dino_wm.utils.get_model import get_model\n",
    "from dino_wm.planning.objectives import create_objective_fn\n",
    "from dino_wm.planning.mpc import MPCPlanner\n",
    "from dino_wm.planning.cem import CEMPlanner\n",
    "from einops import rearrange, repeat\n",
    "import einops\n",
    "from dino_wm.utils.utils import move_to_device\n",
    "from dino_wm.env.venv import SubprocVectorEnv\n",
    "# import gymnasium as gym\n",
    "# import gym_pusht\n",
    "# from gym_pusht.envs import PushTEnv\n",
    "import gym\n",
    "import dino_wm.env\n",
    "import torch\n",
    "import numpy as np\n",
    "from dino_wm.models.visual_world_model import VWorldModel\n",
    "from dino_wm.utils.preprocessor import Preprocessor\n",
    "import imageio\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1785c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_envs = 1\n",
    "frameskip = 5\n",
    "horizon = 5\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c96168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18685 rollouts\n",
      "Loaded 21 rollouts\n",
      "Resuming from epoch 2: /home/ianchuang/dino_wm/outputs/checkpoints/outputs/pusht/checkpoints/model_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ianchuang/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_action_repeat: 1\n",
      "num_proprio_repeat: 1\n",
      "proprio encoder: ProprioceptiveEmbedding(\n",
      "  (patch_embed): Conv1d(4, 10, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "action encoder: ProprioceptiveEmbedding(\n",
      "  (patch_embed): Conv1d(10, 10, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "proprio_dim: 10, after repeat: 10\n",
      "action_dim: 10, after repeat: 10\n",
      "emb_dim: 404\n",
      "Model emb_dim:  404\n",
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "wm, dataset, data_preprocessor = get_model(\"/home/ianchuang/dino_wm/outputs/checkpoints\", \"pusht\", device)\n",
    "wm : VWorldModel = wm\n",
    "wm.to(device)\n",
    "print(\"loaded model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828242cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gym.vector.SyncVectorEnv\n",
    "# env = gym.vector.AsyncVectorEnv(\n",
    "#     [\n",
    "#         lambda: gym.make(\n",
    "#             \"gym_pusht/PushT-v0\", \n",
    "#             disable_env_checker=True, \n",
    "#             relative=True,\n",
    "#             legacy=False,\n",
    "#             action_scale=100,\n",
    "#             obs_type=\"visual_proprio\", \n",
    "#             render_mode=\"rgb_array\",\n",
    "#             observation_width=224,\n",
    "#             observation_height=224,\n",
    "#         )\n",
    "#         for _ in range(n_envs)\n",
    "#     ]\n",
    "# )\n",
    "# obs, info = env.reset()\n",
    "\n",
    "# env = gym.vector.AsyncVectorEnv(\n",
    "#     [\n",
    "#         lambda: gym.make(\n",
    "#             \"ian-pusht\", \n",
    "#             with_velocity=True,\n",
    "#             with_target=True,\n",
    "#         )\n",
    "#         for _ in range(n_envs)\n",
    "#     ]\n",
    "# )\n",
    "# obs, info = env.reset()\n",
    "env = gym.make(\n",
    "    \"ian-pusht\", \n",
    "    with_velocity=True,\n",
    "    with_target=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0721e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs['visual'] shape: torch.Size([25, 3, 224, 224])\n",
      "obs['proprio'] shape: torch.Size([25, 4])\n",
      "actions shape: torch.Size([25, 2])\n",
      "state shape: torch.Size([25, 7])\n",
      "start_obs['visual'] shape: torch.Size([1, 1, 3, 224, 224])\n",
      "start_obs['proprio'] shape: torch.Size([1, 1, 4])\n",
      "end_obs['visual'] shape: torch.Size([1, 1, 3, 224, 224])\n",
      "end_obs['proprio'] shape: torch.Size([1, 1, 4])\n",
      "actions shape: torch.Size([1, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "obs, actions, state, info = dataset[0]\n",
    "\n",
    "obs = {\n",
    "    k: v[-(frameskip*horizon):]\n",
    "    for k, v in obs.items()\n",
    "}\n",
    "actions = actions[-(frameskip*horizon):]\n",
    "state = state[-(frameskip*horizon):]\n",
    "print(f\"obs['visual'] shape: {obs['visual'].shape}\")\n",
    "print(f\"obs['proprio'] shape: {obs['proprio'].shape}\")\n",
    "print(f\"actions shape: {actions.shape}\")\n",
    "print(f\"state shape: {state.shape}\")\n",
    "\n",
    "start_obs = {}\n",
    "start_obs['visual'] = obs['visual'][:1].unsqueeze(0).repeat(n_envs, 1, 1, 1, 1)\n",
    "start_obs['proprio'] = obs['proprio'][:1].unsqueeze(0).repeat(n_envs, 1, 1)\n",
    "end_obs = {}\n",
    "end_obs['visual'] = obs['visual'][-1:].unsqueeze(0).repeat(n_envs, 1, 1, 1, 1)\n",
    "end_obs['proprio'] = obs['proprio'][-1:].unsqueeze(0).repeat(n_envs, 1, 1)\n",
    "print(f\"start_obs['visual'] shape: {start_obs['visual'].shape}\")\n",
    "print(f\"start_obs['proprio'] shape: {start_obs['proprio'].shape}\")\n",
    "print(f\"end_obs['visual'] shape: {end_obs['visual'].shape}\")\n",
    "print(f\"end_obs['proprio'] shape: {end_obs['proprio'].shape}\")\n",
    "\n",
    "actions = einops.rearrange(actions, \"(h f) a -> h (f a)\", f=frameskip, h=horizon).unsqueeze(0).repeat(n_envs, 1, 1)\n",
    "print(f\"actions shape: {actions.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3fcc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inverse_normalize(mean, std):\n",
    "    inv_std = [1.0/s for s in std]\n",
    "    inv_mean = [-m/s for m, s in zip(mean, std)]\n",
    "    return transforms.Normalize(mean=inv_mean, std=inv_std)\n",
    "inverse_normalize = get_inverse_normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "\n",
    "imageio.mimsave(\n",
    "    \"dataset.mp4\",\n",
    "    einops.rearrange(inverse_normalize(obs['visual']) * 255, \"b c h w -> b h w c\").cpu().numpy().astype(np.uint8),\n",
    "    fps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ad313cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "# env.reset(options={\n",
    "#     'reset_to_state': state[0],\n",
    "# })\n",
    "env.reset()\n",
    "env.unwrapped._set_state(state[0].tolist())\n",
    "env_actions = einops.rearrange(actions, \"b h (f a) -> b (h f) a\", f=frameskip)\n",
    "env_actions = data_preprocessor.denormalize_actions(env_actions)\n",
    "for i in range(env_actions.shape[1]):\n",
    "    # obs, reward, terminated, truncated, info = env.step(env_actions[:, i])\n",
    "    obs, reward, done, info = env.step(env_actions[:, i].squeeze(0).tolist())\n",
    "    images.append(obs['visual'])\n",
    "\n",
    "# imageio.mimsave(\n",
    "#     \"env.mp4\",\n",
    "#     einops.rearrange(np.array(images), \"n b h w c -> n h (b w) c\"),\n",
    "#     fps=10,\n",
    "# )\n",
    "imageio.mimsave(\n",
    "    \"env.mp4\",\n",
    "    images,\n",
    "    fps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be73dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_obs['visual'] shape: torch.Size([1, 1, 3, 224, 224])\n",
      "start_obs['proprio'] shape: torch.Size([1, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_obs = {\n",
    "    k: v.to(device)\n",
    "    for k, v in start_obs.items()\n",
    "}\n",
    "actions = actions.to(device)\n",
    "print(f\"start_obs['visual'] shape: {start_obs['visual'].shape}\")\n",
    "print(f\"start_obs['proprio'] shape: {start_obs['proprio'].shape}\")\n",
    "z_obs, z = wm.rollout(start_obs, actions)\n",
    "\n",
    "wm_obs, diff = wm.decode_obs(z_obs)\n",
    "wm_images = wm_obs['visual'].squeeze(0)\n",
    "wm_images = torch.clamp(wm_images, 0, 1)\n",
    "\n",
    "imageio.mimsave(\n",
    "    \"imagination.mp4\",\n",
    "    einops.rearrange(inverse_normalize(wm_images) * 255, \"b c h w -> b h w c\").detach().cpu().numpy().astype(np.uint8),\n",
    "    fps=10 // 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48703da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout time: 0.04827570915222168\n",
      "rollout time: 3.7375757694244385\n",
      "rollout time: 3.7386913299560547\n",
      "rollout time: 3.7443952560424805\n",
      "rollout time: 3.7449162006378174\n",
      "rollout time: 3.7463669776916504\n",
      "rollout time: 3.741705894470215\n",
      "rollout time: 3.741791248321533\n",
      "rollout time: 3.742806911468506\n",
      "rollout time: 3.7435216903686523\n",
      "rollout time: 3.744086742401123\n",
      "rollout time: 3.7441606521606445\n",
      "rollout time: 3.7438690662384033\n",
      "rollout time: 3.746615171432495\n",
      "rollout time: 3.7493979930877686\n",
      "rollout time: 3.7483277320861816\n",
      "rollout time: 3.7494242191314697\n",
      "rollout time: 3.7479050159454346\n",
      "rollout time: 3.7498514652252197\n",
      "rollout time: 3.7519612312316895\n",
      "rollout time: 3.7496023178100586\n",
      "rollout time: 3.7497689723968506\n",
      "rollout time: 3.7488958835601807\n",
      "rollout time: 3.7490274906158447\n",
      "rollout time: 3.7510132789611816\n",
      "rollout time: 3.745695114135742\n",
      "rollout time: 3.7507882118225098\n",
      "rollout time: 3.751906156539917\n",
      "rollout time: 3.7477924823760986\n",
      "rollout time: 3.7499489784240723\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def cem(wm: VWorldModel, start_obs, end_obs, actions= None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        obs_0: (B, T, obs_dim) torch.Tensor\n",
    "        obs_g: (B, T, obs_dim) torch.Tensor\n",
    "        actions: (B, H, action_dim) torch.Tensor\n",
    "    \"\"\"\n",
    "    objective_fn = create_objective_fn(alpha=1, base=1, mode=\"last\")\n",
    "    topk = 30\n",
    "    var_scale = 1.0\n",
    "    opt_steps = 30\n",
    "    num_samples = 300\n",
    "    sigma = var_scale * torch.ones(n_envs, horizon, wm.action_dim)\n",
    "    mu = torch.zeros(n_envs, horizon, wm.action_dim)\n",
    "    if actions is not None:\n",
    "        mu[:, :actions.shape[1], :] = actions\n",
    "\n",
    "    mu = mu.to(device)\n",
    "    sigma = sigma.to(device)\n",
    "    start_obs = {k: v.to(device) for k, v in start_obs.items()}\n",
    "    end_obs = {k: v.to(device) for k, v in end_obs.items()}\n",
    "    end_z = wm.encode_obs(end_obs)\n",
    "    for env_idx in range(n_envs):\n",
    "        env_start_z = {\n",
    "            k: repeat(v[env_idx].unsqueeze(0), \"1 ... -> n ...\", n=num_samples)\n",
    "            for k, v in start_obs.items()\n",
    "        }\n",
    "        env_end_z = {\n",
    "            k: repeat(v[env_idx].unsqueeze(0), \"1 ... -> n ...\", n=num_samples)\n",
    "            for k, v in end_z.items()\n",
    "        }\n",
    "        losses = []\n",
    "        for _ in range(opt_steps):            \n",
    "            action = torch.randn(\n",
    "                num_samples, horizon, wm.action_dim, device=device\n",
    "            )*sigma[env_idx] + mu[env_idx]\n",
    "            action[0] = mu[env_idx]  # optional: make the first one mu itself\n",
    "            with torch.no_grad():\n",
    "                start_time = time.time()\n",
    "                rollout_z, _ = wm.rollout(\n",
    "                    obs_0=env_start_z,\n",
    "                    act=action,\n",
    "                )\n",
    "                print(f\"rollout time: {time.time() - start_time}\")\n",
    "                loss = objective_fn(rollout_z, env_end_z)\n",
    "                losses.append(loss)\n",
    "                topk_idx = torch.argsort(loss)[: topk]\n",
    "                topk_action = action[topk_idx]\n",
    "                mu[env_idx] = topk_action.mean(dim=0)\n",
    "                sigma[env_idx] = topk_action.std(dim=0)\n",
    "\n",
    "    return mu\n",
    "    \n",
    "wm_actions = cem(wm, start_obs, end_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f6081",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m env\u001b[38;5;241m.\u001b[39munwrapped\u001b[38;5;241m.\u001b[39m_set_state(state[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m      4\u001b[0m env_actions \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(actions, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb h (f a) -> b (h f) a\u001b[39m\u001b[38;5;124m\"\u001b[39m, f\u001b[38;5;241m=\u001b[39mframeskip)\n\u001b[0;32m----> 5\u001b[0m env_actions \u001b[38;5;241m=\u001b[39m \u001b[43mdata_preprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenormalize_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(env_actions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m      7\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(env_actions[:, i]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/dino_wm/dino_wm/utils/preprocessor.py:32\u001b[0m, in \u001b[0;36mPreprocessor.denormalize_actions\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdenormalize_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, actions):\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    actions: (b, t, action_dim)  \u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mactions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_std\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_mean\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "env.reset()\n",
    "env.unwrapped._set_state(state[0].tolist())\n",
    "env_actions = einops.rearrange(wm_actions, \"b h (f a) -> b (h f) a\", f=frameskip)\n",
    "env_actions = data_preprocessor.denormalize_actions(env_actions)\n",
    "for i in range(env_actions.shape[1]):\n",
    "    obs, reward, done, info = env.step(env_actions[:, i].squeeze(0).tolist())\n",
    "    images.append(obs['visual'])\n",
    "imageio.mimsave(\n",
    "    \"wm_env.mp4\",\n",
    "    images,\n",
    "    fps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e39b62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino_wm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
